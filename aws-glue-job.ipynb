{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Job for AWS Glue Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "Current iam_role is None\n",
      "iam_role has been set to arn:aws:iam::891377119959:role/glue-synth-medical.\n",
      "Previous region: us-east-1\n",
      "Setting new region to: us-east-1\n",
      "Region is set to: us-east-1\n"
     ]
    }
   ],
   "source": [
    "%iam_role arn:aws:iam::891377119959:role/glue-synth-medical\n",
    "%region us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create a Glue session for the kernel.\n",
      "Session Type: etl\n",
      "Worker Type: G.1X\n",
      "Number of Workers: 5\n",
      "Session ID: 7b9c6a97-61a5-4c7f-bf61-6ff2f597e7f1\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 1.0.4\n",
      "--enable-glue-datacatalog true\n",
      "Waiting for session 7b9c6a97-61a5-4c7f-bf61-6ff2f597e7f1 to get into ready status...\n",
      "Session 7b9c6a97-61a5-4c7f-bf61-6ff2f597e7f1 has been created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import col, to_date, DataFrame\n",
    "from awsglue.context import GlueContext\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# from awsglue.transforms import *\n",
    "# from awsglue.utils import getResolvedOptions\n",
    "# from awsglue import DynamicFrame\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATABASE = \"cmsdesynpuf1k\"\n",
    "VOCABULARY = \"XXXX\"\n",
    "\n",
    "def load_medical_data(\n",
    "    table_id: str,\n",
    "    database_name: str = DATABASE,\n",
    ") -> DataFrame:\n",
    "    df = load_table_to_df(table_id, database_name=database_name)\n",
    "    df = cast_date_columns_and_drop_timestamp(df)\n",
    "    df.createOrReplaceTempView(table_id)\n",
    "    return df\n",
    "\n",
    "def load_vocabulary(\n",
    "    table_id: str,\n",
    "    database_name: str = VOCABULARY,\n",
    "    ) -> DataFrame:\n",
    "    df = load_table_to_df(table_id, database_name=database_name)\n",
    "    df.createOrReplaceTempView(table_id)\n",
    "    return df \n",
    "\n",
    "def load_table_to_df(table_id: str, database_name: str) -> DataFrame:\n",
    "    df = glueContext.create_data_frame_from_catalog(\n",
    "        database=database_name,\n",
    "        table_name=get_table_name(table_id),\n",
    "        transformation_ctx=f\"load_{table_id}_DF\",\n",
    "        useSparkDataSource=True,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def get_table_name(table_id: str) -> str:\n",
    "    table_name_pattern = f\"cdm_{table_id}_csv_bz2\"\n",
    "    \n",
    "    glue_client = boto3.client(\"glue\")\n",
    "    matching_tables = glue_client.get_tables(\n",
    "        DatabaseName=DATABASE,\n",
    "        Expression=table_name_pattern\n",
    "    )['TableList']\n",
    "    \n",
    "    if len(matching_tables) == 0:\n",
    "        raise ValueError(f\"Table {table_id} not found\")\n",
    "    if len(matching_tables) > 1:\n",
    "        raise ValueError(f\"Multiple tables found for {table_id}\")\n",
    "    return matching_tables[0][\"Name\"]\n",
    "\n",
    "def cast_date_columns_and_drop_timestamp(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Transform date columns from bigint to date and drop columns \n",
    "    specifying time of day (they end with 00:00:00)\"\"\"\n",
    "    columns_out = []\n",
    "    for c in df.columns:\n",
    "        if c.endswith(\"00:00:00\"):\n",
    "            continue\n",
    "        elif c.endswith(\"_date\"):\n",
    "            c_out = to_date(col(c).cast('string'), 'yyyyMMdd').alias(c)\n",
    "        else:\n",
    "            c_out = col(c)\n",
    "        columns_out.append(c_out)\n",
    "                \n",
    "    return df.select(columns_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# condition_df = load_medical_data(\"condition_occurrence\")\n",
    "# era_start_date = condition_df.select('condition_start_date').toPandas()\n",
    "# plt.hist(era_start_date, bins=50, alpha=0.7, color='blue')\n",
    "# %matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n"
     ]
    }
   ],
   "source": [
    "death_df = load_medical_data(\"death\")\n",
    "person_df = load_medical_data(\"person\")\n",
    "condition_df = load_medical_data(\"condition_occurrence\")\n",
    "observation_period_df = load_medical_data(\"observation_period\")\n",
    "# vocabulary_df = load_medical_data(\"xxxx\", database_name=VOCABULARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sql_create_cohort_script = \"\"\"\n",
    "WITH selected_condition AS (\n",
    "    SELECT\n",
    "        person_id,\n",
    "        condition_concept_id,\n",
    "        condition_start_date\n",
    "    FROM \n",
    "        condition_occurrence\n",
    "    WHERE\n",
    "        condition_concept_id = 320128\n",
    ")\n",
    "SELECT\n",
    "    sc.person_id,\n",
    "    sc.condition_concept_id,\n",
    "    sc.condition_start_date,\n",
    "    CASE\n",
    "        WHEN d.death_date IS NULL THEN 1\n",
    "        ELSE 0\n",
    "    END AS dead\n",
    "FROM\n",
    "    selected_condition AS sc\n",
    "    INNER JOIN \n",
    "    observation_period AS op\n",
    "    ON sc.person_id = op.person_id    \n",
    "    AND DATEDIFF(sc.condition_start_date, op.observation_period_start_date) > 360\n",
    "    AND DATEDIFF(op.observation_period_end_date, sc.condition_start_date) > 360\n",
    "\n",
    "    LEFT JOIN\n",
    "    death as d\n",
    "    ON sc.person_id = d.person_id\n",
    "    AND DATEDIFF(sc.condition_start_date, d.death_date) > 360\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "sql_add_features_script = \"\"\"\n",
    "SELECT\n",
    "    c.person_id,\n",
    "    c.dead,\n",
    "    p.gender_concept_id,\n",
    "    p.race_concept_id,\n",
    "    p.ethnicity_concept_id,\n",
    "    p.year_of_birth,\n",
    "    p.location_id\n",
    "FROM\n",
    "    cohort as c\n",
    "    JOIN \n",
    "    person as p\n",
    "    ON c.person_id = p.person_id\n",
    ";\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cohort = spark.sql(sql_create_cohort_script)\n",
    "cohort.createOrReplaceTempView(\"cohort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = spark.sql(sql_add_features_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(features.write\n",
    " .format(\"parquet\")\n",
    " .option(\"compression\", \"snappy\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"s3://synth-medical/data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
